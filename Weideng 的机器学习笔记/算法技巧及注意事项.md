# 算法技巧及注意事项

## 项目结构

### 基本结构

- 项目说明（Project Description）

	- 背景
	- 目标
	- 数据
	- 策略

- 空间分析（Space Analysis）

	分析数据与模型的空间，构建满足空间条件的策略实现代码。（预先分析）

	- 外存

	- 内存

	- 显存

- 导入包（Import Package）

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import math
import os

import torch
import torch.nn as nn
from torch.utils.data import random_split, Dataset, DataLoader
```

- 配置（Configuration ）

	使用 `Config` 类，设置类变量保存配置参数和超参数。
	
	- 使用字典则无代码提示。
	- 需要频繁修改的项靠下放。
	- 配置只包含基本不变的参数。

```python
class Config:   # 配置类
    # environment
    device = 'cuda' if torch.cuda.is_available() else 'cpu'   # 类变量
    seed = 923
    save_path = './model.ckpt'
    
    # data path
    data_path = './data'
    
    # NN structure
    
    # ...
    
    # training
    n_example = math.inf
    n_epoch = 1000
    early_stop_epoch = 300
    batch_size = 256
     
    # local or cloud
    here_path = os.getcwd()
    if 'kaggle/working' in here_path: 
        # cloud items
    else:
        # local items
        
	# local or could runing test
    runing_test = True   # need be modified by hand
    if runing_test:
	    n_example = 20
    	n_epoch = 10
    
    # 必要时可扩展
	def __init__(self):   
        pass

print(f"Using {Config.device} device")

# 扩展
class ConfigTest:
    pass
```

- 通用操作（General Operation）

```python
def same_seed(seed): 
    torch.backends.cudnn.deterministic = True   # 卷积都使用默认的卷积算法
    torch.backends.cudnn.benchmark = False   # 关闭系统卷积算法选择优化（带随机性）
    np.random.seed(seed)   # 为随机算法设置种子。
    torch.manual_seed(seed)   # 为 CPU 设置种子。
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)   # 为所有 GPU 设置种子。

def split_train_valid(data, valid_ratio, seed):
    valid_size = int(len(data) * valid_ratio)
    train_size = len(data) - valid_size
    train_set, valid_set = random_split(data, [train_size, valid_size], generator=torch.Generator().manual_seed(seed))
    return train_set, valid_set
```

- 数据处理（Data Processing）

	多使用函数，便于四处调用修改。

- 数据预备（Data Preparation）

	构建 Dataset，Dataloader 。

- 模型结构（Model Structure）

- 训练流程（Training Loop）

- 测试、预测（Testing，Prediction）

- 时间分析（Time Analysis）

	进行时间测试，反复修改代码以提升效率。（反复运行并分析）

	- 数据处理时间
	- 训练时间
	- 测试时间
	
- 表现分析（Performance Analysis）

  分析模型的表现。

### 工程风格

使用 main 函数统筹各部分函数：

- 便于清晰描述项目流程，也便于扩展到多参数对比训练，多批次数据训练等。
- 简明，模块化，易扩展，但不便于反复调试，每次调试都要重复计算。
- 输出都集中到 main 函数底部。

```python
def main():
	same_seed(Config.seed)
	...
	...

# begin    
main()   # 扩展时能被当作一般函数调用

# 扩展
# def project()
Config.xxx
main(xxx)
Config.xxx
main(xxx)
```

### Jupyter Notebook 风格

不使用 main 函数统筹函数，而是直接使用 Jupyter Cell 统筹流程：

- 不必每次调试都从头开始运行，可以反复利用已经计算出的结果和输出测试信息。
- 变量命名要准确，Notebook 风格会存在大量全局变量。
- 分散输出，便于描述思路。

整体结构要按照基本结构布置，以便于修改为函数或类，从而扩展到工程风格，应对复杂情况。

### 混合风格

- 使用基本结构。
- 工程风格为主，但不使用 main 函数统筹项目。
- 将 main 函数应当包含的内容按照 Notebook 风格分散开，为单元编写整体函数，于单元内调用。（相当于将全局当作一个 main 函数）
	- 便于单元测试，分散输出和利用已有计算信息。
	- 便于快速将各单元函数和操作集中到 main 函数中，扩展到工程风格。

```python 
# 一般 begin 位置，相当于把全局当作 main 。

# Cell 1

def operation1():
    pass

operation1()   # 调用

# Cell 2

...
operation2   # 不是函数，是 notebook 风格的全局域的操作。
...

# Cell 3

def other_functions():
    pass

def operation3():
    other_functions()

operation3()   # 调用

...

# 扩展时：
def main():   # 或者不使用 main，而使用其它的名字，继续扩展。
    operation1()
    operation2
    operation3()
    
main()   # 扩展时 begin 位置。
```

## 输出刷新

原生方法只能单行刷新，多行刷新需要使用库。

- `\r` 可以移动到当前行开头，从而刷新输出。
- 刷新的行不能有换行符，可在 `print()` 内指定 `end=''` 。
- 刷新行后的第一个非刷新行需要在开头添加换行符。

```python
print(f'\r[{epoch + 1}/{Config.n_epoch}] train loss = {train_mean_loss:4f}, valid loss = {valid_mean_loss:.4f}', end='')

print(f'\n[{epoch + 1}/{Config.n_epoch}] save model : train loss = {train_mean_loss:.4f}, valid loss = {valid_mean_loss:.4f}')
```

## 运行测试

更换环境要重新测试：

- 本地
- 云端

程序流程测试：

- 小数据量，小 epoch 。

  项目构建全程使用，测试程序问题。

- 全数据量，小 epoch 。

  项目构建完毕后使用，主要测试全数据下是否有数据加载错误。

  - 数据处理在小数据量已经测试过，可适当删减，以加快训练速度。
  - 大 epoch 不必测试，因为小 epoch 已经足够。

- 多步输入数据训练时，要测试最后一步结尾不足一步跨度的数据。

## 空间控制

- 进行空间分析。

- 及时回收大空间变量。

  可使用 gc 模块。

```python
import gc

# 删除变量引用
del variable1, variable2   # 引用计数

# 立即回收垃圾
gc.collect()
```

- 全体数据分步读取，输入项目。（分步内仍能保证数据有足够的随机性时使用）

  - 每个分步跑完一遍 epoch 后，模型遇到的是全新的数据，训练不稳定。
  - 形成 batch 时只能每一步内 shuffle ，不能全局 shuffle 。
  - 此时建议缩减 epoch ，增大全体数据的循环次数。（数据处理会增加）
  - 训练流程变复杂，需要注意 epoch 数量的处理。
- 训练时用到再读取和处理。（数据处理简单，且 epoch 较少时采用）

  - 多个 epoch 会反复 I/O 和处理数据，反复 I/O 和复杂的处理过程，会耗费大量的时间。
  - I/O 是非常耗时的，可能在 epoch 中反复数据处理消耗的时间还没有一次 I/O 多。
- 将处理后的数据存入文件并构造索引，用到时再读取。（数据处理复杂，样本较大，epoch 较多时采用）
  - 利用外存空间，为了提升 I/O 效率，需要合理设置文件的大小和构造索引。
  - 当每次取数据只读取存储的文件的一小部分时，可能 I/O 次数会非常多。

```python
# 张量存储与读取
torch.save(obj, 'xxx.pt')
torch.load('xxx.pt')
```

- 调整数据类型。

## 时间控制



## Kaggle 使用

- 时长
	- CPU 与 GPU，每周限制 40 小时，每次 session 限制12 小时。
	- 后台可以同时运行两个 session 。
	- 计时包括交互运行时间和后台运行时间。
	- 关闭页面前要记得关闭 session ，否则会一直占用运行时长直到一个小时超时。
- 存储
	- 外存 70 G 。
	- 内存 13 G 。（环境本身约占 500 M，建议以 1 G 计算）
	- 显存 16 G 。
- 技巧
	- Kaggle 不会在 12 小时限制前终止正在运行的程序。
	- 当时长快用完时，在后台跑一个 12 小时的程序，等于白嫖约 12 小时；跑两个 12 小时的程序，等于白嫖约 24 小时。

## 杂项

- 测试数据在测试时再构建。

- PyTorch 中方法名末尾如果带下划线，表示会修改变量本身（in-place）：`.abs_(), .abs()  ` 。
- 编码测试使用小部分数据集和小参数，测试完后再正式训练。
- `assert` 可用于调试。
- 可跑一个 epoch 或一个 batch 以预估总训练时间。
- 云端和本地都要运行测试，因为云端可能有 GPU 等环境问题。