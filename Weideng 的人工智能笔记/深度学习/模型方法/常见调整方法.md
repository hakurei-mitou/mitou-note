# 基本调整方法

## 问题分析流程

- 若训练集损失大

	- 模型偏见

		使用更复杂的模型。

		- 若复杂模型仍不管用

			将训练数据划分为测试集和验证集用于选择合适的模型。

	- 最优化问题

		更改最优化方法。

- 若训练集损失小，测试集损失小

	- 是为理想结果。

- 若训练集损失小，测试集损失大

	- 过拟合
		- 使用更多训练数据。
		- 减少模型参数。
		- 简化模型。
	- 模型使用错误。

## 验证集

validation 也可以看做是不同于梯度下降等方法的特殊的对模型的训练方式。当使用验证集时，模型仍可能过拟合。

## 类别表示

分类时，多分类不要单个数字表示一个类别，因为相邻数字间具有相邻关系，尽量采用单位向量的方式表示一个类别。（One-hot）

## 随机化

随机化增加模型探索的能力，一般有以下方法：

### Shuffling

打乱训练数据。

机器学习假设数据符合独立同分布，即每个样本的出现都是随机的。

如果不打乱：

- 可能模型值只学到数据的顺序信息，如果本身就具有顺序特征的，则不打乱。
- 假设训练数据分为两类，当学习大量连续的第一类数据，容易对第一类过拟合，当学习大量连续的第二类数据时，又容易对第二类过拟合，从而产生训练的抖动。

### Dropout

随机使某些神经元失活。

### Gradient Noise

每次计算梯度时，按某个分布为梯度加上“噪音”值，该值应当随迭代进行而变小。

比如加上高斯分布：
$$
\begin{cases}
\boldsymbol g_t = \boldsymbol g_t + N(0, \sigma_t^2) \\\\
\sigma_t = \frac {c} {(1 + t)^r}
\end{cases}
$$

## Curriculum Learning

- 先用没有噪音的简单的数据训练模型，以便找到先一个较平坦的局部最小值。
- 再用有噪音的复杂的数据训练模型，从而从平坦的局部最小值附近去找一个更优的解。

## Fine-tuning

使用已经**预训练（pre-train）**好的模型，以节约资源。