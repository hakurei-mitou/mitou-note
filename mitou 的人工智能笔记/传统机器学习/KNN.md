# K 最近邻算法（K-Nearest Neighbor， KNN）

KNN **分类算法**是数据挖掘分类技术中最简单的方法之一。

==其根据最接近样本的 K 个最邻近值来分类样本。==

样本容量大时才能保证准确度。

## 距离计算

选取某种距离度量，以衡量两个样本间的相似度。

对每一个预测样本，要将其与所有其它样本计算距离，并选取前 K 个样本作为判断依据。

前 K 个样本所含最多的种类即预测种类。

## K 值选取

- **二分类时**，K 一般选取为奇数，避免出现最多的种类数相同的情形。
- 设数据量为 $n$，一般选取 $K \le \sqrt{n}$。
- 可通过交叉验证的方式，从一个较小的 K 值开始，逐步增大 K 值，从而选取。

## 算法

1. 选取 K 值。
2. 计算待预测样本与其余所有样本的距离。
3. 选取前 K 个距离值对应的样本，找到数量最多的样本类别。
4. 输出预测值。

## 特点

KNN是一种**非参**的，**惰性**的算法模型。

非参：这个算法不需要参数，这意味着这个模型不会对数据做出任何的假设。

惰性：没有训练数据的过程。

## 优劣

优：

- 简单易用。
- 惰性，不需训练。
- 对异常值不敏感。

劣：

- 内存占用大，要存储所有训练数据。
- 算法复杂度大，预测阶段可能很慢。
- 样本不平衡，即某一类样本数量占很大，可能影响正确性。